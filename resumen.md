## Resumen

Trabajos recientes han demostrado avances sustanciales en muchas tareas de PNL  y _benchmarks_ mediante el pre-entrernamiento sobre un gran corpus de texto seguido de un _fine-tuning_ en una tarea específica. Si bien la arquitectura es típicamente agnostica frente a la tarea, este método aún requiere un_fine-tuning_ para la trea especifica sobre conjuntos de datos de miles o decenas de miles de ejemplos. En contraste, los humanos generalmente pueden realizar una nueva tarea de lenguaje a partir de solo unos pocos ejemplos o de instrucciones simples, - algo que los sistemas de PNL actuales todavía tienen muchas dificultades para hacer. Aquí mostramos que _escalar _ mejora en gran medida el rendimiento de los modelos de lenguaje agnósticos a las tareas, el perfomance de pocos intentos (_few shots_), y a veces incluso alcanzando niveles de competitividad con enfoques de vanguardia de _fine tuning_ anteriores. Específicamente, entrenamos GPT-3, un modelo de lenguaje autorregresivo con 175 mil millones de parámetros, 10 veces más que cualquier modelo de lenguaje _non-sparse_ anterior, y probamos su rendimiento en la configuración de  pocos intentos. Para todas las tareas, se aplica GPT-3 con tareas y demostraciones de _pocos intentos_ especificadas únicamente a través de la interacción de texto con el modelo, sin actualizaciones de gradiente o _fine tuning_. GPT-3 alcanza un alto rendimiento en diferentes conjuntos de datos de PNL, incluidas las tareas de traducción, responder preguntas, así como varias tareas que requieren razonamiento sobre la marcha o adaptación de dominio, tales como descifrar palabras, usar una palabra nueva en una oración, o realizar aritmética de 3 dígitos. Al mismo tiempo, también identificamos algunos conjuntos de datos donde el aprendizaje de _pocos intentos_ de GPT-3 todavía tiene dificultades, así como algunos conjuntos de datos donde GPT-3 enfrenta problemas metodológicos relacionados con el entrenamiento basado en corpus grandes de la web. Finalmente, encontramos que GPT-3 puede generar muestras de artículos de noticias que los evaluadores humanos tienen dificultades para distinguir de los artículos escritos por humanos. Discutimos los impactos sociales más amplios de este hallazgo y de GPT-3 en general.
